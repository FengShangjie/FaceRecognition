{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 制作相机的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "face_xml = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_xml = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "flag = 1\n",
    "while(cap.isOpened()):\n",
    "    ret_flag , Vshow = cap.read()\n",
    "    gray = cv2.cvtColor(Vshow, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_xml.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(Vshow, (x,y),(x+w, y+h),(255,255,255), 1)\n",
    "        roi_face = gray[y:y+h,x:x+w]\n",
    "        roi_color = Vshow[y:y+h,x:x+w]\n",
    "    cv2.imshow(\"Capture_Test\",Vshow)\n",
    "    k = cv2.waitKey(1) & 0xFF #每帧数据延时 1ms，延时不能为 0，否则读取的结果会是静态帧\n",
    "    if  k == ord('s'):  #若检测到按键 ‘s’，打印字符串\n",
    "        \n",
    "        print(cap.get(3))\n",
    "        print(cap.get(4))\n",
    "        \n",
    "    elif k == ord('q'): #若检测到按键 ‘q’，退出\n",
    "        cv2.imwrite(\"x1.jpg\",Vshow)\n",
    "        break\n",
    "cap.release() #释放摄像头\n",
    "cv2.destroyAllWindows()#删除建立的全部窗口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开启录像的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# 选取摄像头，0为笔记本内置的摄像头，1,2···为外接的摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(3,480)\n",
    "#cap.set(4,320)\n",
    "# cap.set(3,1080)\n",
    "# cap.set(4,720)\n",
    "\n",
    "# 为保存视频做准备\n",
    "fourcc = cv2.VideoWriter_fourcc(\"D\", \"I\", \"B\", \" \")\n",
    "# 第三个参数则是镜头快慢的，20为正常，小于二十为慢镜头\n",
    "out = cv2.VideoWriter('mm.avi', fourcc,20,(640,480))\n",
    "while True:\n",
    "    # 一帧一帧的获取图像\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # 在帧上进行操作\n",
    "        # gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        # 开始保存视频\n",
    "        out.write(frame)\n",
    "        # 显示结果帧\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# 释放摄像头资源\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将录像处理为图片的功能\n",
    "> 先安装ffmpeg <br\\> \n",
    "> 然后使用命令ffmpeg -i 1.mp4 image%d.jpg解析图片<br\\> \n",
    "> 将人脸部分截下<br\\> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok,finish\n"
     ]
    }
   ],
   "source": [
    "# 1 load xml 2 load jpg 3 haar gray 4 detect 5 draw\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "# load xml 1 file name\n",
    "face_xml = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# eye_xml = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "# load jpg\n",
    "path = \".\\\\fsj\\\\\"\n",
    "dirs = os.listdir(path)\n",
    "index = 0\n",
    "for dir in dirs:\n",
    "    if dir.split('.')[1] == 'jpg':\n",
    "        img = cv2.imread(path + dir)\n",
    "    #     cv2.imshow('src',img)\n",
    "        # haar gray\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # detect faces 1 data 2 scale 3 5\n",
    "        faces = face_xml.detectMultiScale(gray,1.3,5)\n",
    "        # draw\n",
    "    #     index = 0\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_face = gray[y:y+h,x:x+w]\n",
    "            roi_color = img[y:y+h,x:x+w]\n",
    "            fileName = 'exm\\\\' + str(index) + '.jpg'\n",
    "            cv2.imwrite(fileName,roi_color)\n",
    "            index = index+1\n",
    "        \n",
    "    #         index = index + 1\n",
    "            # 1 gray\n",
    "    #         eyes = eye_xml.detectMultiScale(roi_face)\n",
    "    #         print('eye=',len(eyes))\n",
    "            #for (e_x,e_y,e_w,e_h) in eyes:\n",
    "                #cv2.rectangle(roi_color,(e_x,e_y),(e_x+e_w,e_y+e_h),(0,255,0),2)\n",
    "    #     cv2.imshow('dst',img)\n",
    "    #     cv2.waitKey(0)\n",
    "print(\"ok,finish\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将图片处理为处理的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "path = '.\\\\exm\\\\'\n",
    "dirs = os.listdir(path)\n",
    "for dir in dirs:\n",
    "    filename = path + dir\n",
    "    if dir.split('.')[1] == 'jpg':\n",
    "        img = cv2.imread(filename, 1)\n",
    "        imgInfo = img.shape\n",
    "        #print(imgInfo)\n",
    "        height = imgInfo[0]\n",
    "        width = imgInfo[1]\n",
    "        mode = imgInfo[2]\n",
    "        #1 放大  缩小  2等比例 非等比例\n",
    "        dstHeight = 64\n",
    "        dstWidth = 64   #等比例缩放\n",
    "        #resize的方法最近邻域差值   双线性差值  像素关系采样  立方差值\n",
    "        dst = cv2.resize(img,(dstWidth,dstHeight))   #默认为双线性差值\n",
    "        cv2.imwrite(filename,dst)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  将图片处理为数据，并且将图片的数据归一化，还生成one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  33.   35.   35. ...,   34.   32.   33.]\n",
      "  [  39.  142.  148. ...,  150.  140.  136.]\n",
      "  [  30.  149.  146. ...,  154.  141.  133.]\n",
      "  ..., \n",
      "  [  32.  164.  171. ...,  116.  129.  139.]\n",
      "  [  34.  160.  173. ...,  117.  135.  133.]\n",
      "  [  35.  158.  163. ...,  119.  128.  128.]]\n",
      "\n",
      " [[  34.   29.   32. ...,   26.   32.   29.]\n",
      "  [  33.  149.  153. ...,  134.  136.  137.]\n",
      "  [  29.  153.  151. ...,  136.  143.  138.]\n",
      "  ..., \n",
      "  [  30.  139.  172. ...,   76.   52.   38.]\n",
      "  [  27.  183.  172. ...,   74.   45.   29.]\n",
      "  [  30.  173.  156. ...,   96.   56.   26.]]\n",
      "\n",
      " [[  33.   29.   31. ...,   30.   29.   29.]\n",
      "  [  32.  152.  153. ...,   16.   15.   14.]\n",
      "  [  30.  157.  150. ...,   19.   15.   13.]\n",
      "  ..., \n",
      "  [  30.   63.   67. ...,   63.   65.   73.]\n",
      "  [  26.   61.   69. ...,   57.   65.   68.]\n",
      "  [  29.   60.   61. ...,   51.   60.   60.]]\n",
      "\n",
      " ..., \n",
      " [[ 248.  222.  184. ...,   78.   77.   75.]\n",
      "  [ 235.  208.  178. ...,   79.   79.   80.]\n",
      "  [ 218.  189.  178. ...,   78.   79.   82.]\n",
      "  ..., \n",
      "  [ 237.  238.  239. ...,   78.   82.   85.]\n",
      "  [ 238.  239.  239. ...,   81.   85.   87.]\n",
      "  [ 239.  239.  239. ...,   83.   87.   89.]]\n",
      "\n",
      " [[ 237.  212.  174. ...,   60.   58.   60.]\n",
      "  [ 226.  199.  167. ...,   65.   63.   63.]\n",
      "  [ 212.  181.  166. ...,   68.   65.   63.]\n",
      "  ..., \n",
      "  [ 230.  225.  225. ...,   71.   74.   76.]\n",
      "  [ 228.  223.  223. ...,   73.   75.   75.]\n",
      "  [ 226.  220.  221. ...,   75.   76.   75.]]\n",
      "\n",
      " [[ 190.  170.  130. ...,   48.   48.   51.]\n",
      "  [ 177.  158.  127. ...,   50.   50.   52.]\n",
      "  [ 164.  142.  129. ...,   54.   52.   51.]\n",
      "  ..., \n",
      "  [ 176.  175.  175. ...,   56.   59.   60.]\n",
      "  [ 178.  176.  176. ...,   58.   59.   60.]\n",
      "  [ 180.  177.  177. ...,   59.   60.   59.]]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "path1 = \"exm\\\\\"\n",
    "path2 = \"Pose27_64x64_files\\\\\"\n",
    "dir1 = os.listdir(path1)\n",
    "dir2 = os.listdir(path2)\n",
    "# img = cv2.imread(path1+\"0.jpg\")\n",
    "# gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "i = 0\n",
    "data = np.zeros((275,64,64))\n",
    "label = np.zeros((275,2))\n",
    "for d1 in dir1[0:25]: \n",
    "    if d1.split('.')[1] ==\"jpg\":\n",
    "        img = cv2.imread(path1+d1)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        data[i] = gray\n",
    "        label[i] = np.array([1, 0])\n",
    "        i = i+1\n",
    "        \n",
    "data\n",
    "for d2 in dir2[0:250]:\n",
    "    if d2.split('.')[1] ==\"jpg\":\n",
    "        img = cv2.imread(path2+d2)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        data[i] = gray\n",
    "        label[i] = np.array([0, 1])\n",
    "        i = i+1\n",
    "print(data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 步的 训练损失=0.6728, 测试精度=0.91\n",
      "第 1 步的 训练损失=1.0319, 测试精度=0.91\n",
      "第 2 步的 训练损失=0.6562, 测试精度=0.91\n",
      "第 3 步的 训练损失=0.3468, 测试精度=0.91\n",
      "第 4 步的 训练损失=0.3047, 测试精度=0.91\n",
      "第 5 步的 训练损失=0.3595, 测试精度=0.91\n",
      "第 6 步的 训练损失=0.3105, 测试精度=0.91\n",
      "第 7 步的 训练损失=0.2594, 测试精度=0.91\n",
      "第 8 步的 训练损失=0.2809, 测试精度=0.91\n",
      "第 9 步的 训练损失=0.2598, 测试精度=0.91\n",
      "第 10 步的 训练损失=0.2203, 测试精度=0.91\n",
      "第 11 步的 训练损失=0.1913, 测试精度=0.91\n",
      "第 12 步的 训练损失=0.1731, 测试精度=0.91\n",
      "第 13 步的 训练损失=0.1492, 测试精度=0.91\n",
      "第 14 步的 训练损失=0.1238, 测试精度=0.91\n",
      "第 15 步的 训练损失=0.1070, 测试精度=0.91\n",
      "第 16 步的 训练损失=0.0809, 测试精度=0.92\n",
      "第 17 步的 训练损失=0.0665, 测试精度=0.92\n",
      "第 18 步的 训练损失=0.0567, 测试精度=0.92\n",
      "第 19 步的 训练损失=0.0507, 测试精度=0.93\n",
      "第 20 步的 训练损失=0.0410, 测试精度=0.93\n",
      "第 21 步的 训练损失=0.0329, 测试精度=0.93\n",
      "第 22 步的 训练损失=0.0259, 测试精度=0.94\n",
      "第 23 步的 训练损失=0.0188, 测试精度=0.94\n",
      "第 24 步的 训练损失=0.0127, 测试精度=0.94\n",
      "第 25 步的 训练损失=0.0074, 测试精度=0.94\n",
      "第 26 步的 训练损失=0.0040, 测试精度=0.95\n",
      "第 27 步的 训练损失=0.0028, 测试精度=0.95\n",
      "第 28 步的 训练损失=0.0021, 测试精度=0.95\n",
      "第 29 步的 训练损失=0.0010, 测试精度=0.95\n",
      "第 30 步的 训练损失=0.0012, 测试精度=0.95\n",
      "第 31 步的 训练损失=0.0009, 测试精度=0.95\n",
      "第 32 步的 训练损失=0.0005, 测试精度=0.96\n",
      "第 33 步的 训练损失=0.0008, 测试精度=0.96\n",
      "第 34 步的 训练损失=0.0003, 测试精度=0.96\n",
      "第 35 步的 训练损失=0.0002, 测试精度=0.96\n",
      "第 36 步的 训练损失=0.0003, 测试精度=0.96\n",
      "第 37 步的 训练损失=0.0002, 测试精度=0.96\n",
      "第 38 步的 训练损失=0.0001, 测试精度=0.96\n",
      "第 39 步的 训练损失=0.0001, 测试精度=0.96\n",
      "第 40 步的 训练损失=0.0001, 测试精度=0.96\n",
      "第 41 步的 训练损失=0.0001, 测试精度=0.97\n",
      "第 42 步的 训练损失=0.0001, 测试精度=0.97\n",
      "第 43 步的 训练损失=0.0000, 测试精度=0.97\n",
      "第 44 步的 训练损失=0.0000, 测试精度=0.97\n",
      "第 45 步的 训练损失=0.0000, 测试精度=0.97\n",
      "第 46 步的 训练损失=0.0000, 测试精度=0.97\n",
      "第 47 步的 训练损失=0.0000, 测试精度=0.97\n",
      "第 48 步的 训练损失=0.0000, 测试精度=0.97\n",
      "第 49 步的 训练损失=0.0000, 测试精度=0.97\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(100)\n",
    "test_data = np.random.permutation(data)\n",
    "np.random.seed(100)\n",
    "test_label = np.random.permutation(label)\n",
    "test_data = test_data.reshape(test_data.shape[0], 64, 64, 1).astype(np.float32)/255\n",
    "\n",
    "data_input = tf.placeholder(tf.float32,[None, 64, 64, 1])\n",
    "label_input = tf.placeholder(tf.float32,[None, 2])\n",
    "\n",
    "#创建第一层卷积\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs = data_input,   #输入数据\n",
    "    filters = 32,     #过滤器的个数\n",
    "    kernel_size= [5, 5],    #过滤器的大小\n",
    "    strides = 1,        #步长\n",
    "    padding= 'same',     #表示输出的大小不变，因此要在外围补0两圈\n",
    "    activation= tf.nn.relu  #激活函数\n",
    ")   #生成的形状为[64, 64, 32]\n",
    "#创建第一层池化层(亚采样)\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    inputs = conv1,    #输入的张量\n",
    "    pool_size= [2, 2],   #过滤器的大小\n",
    "    strides = 2     #步长\n",
    ") #生成的形状为[32, 32, 32]\n",
    "\n",
    "#第二层卷积\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs = pool1,\n",
    "    filters = 64,\n",
    "    kernel_size= [5,5],\n",
    "    strides = 1,\n",
    "    padding= 'same',     #表示输出的大小不变，因此要在外围补0两圈\n",
    "    activation = tf.nn.relu\n",
    ") #生成的形状为[32, 32, 64]\n",
    "#第二层池化层\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "    inputs = conv2,\n",
    "    pool_size = [2, 2],\n",
    "    strides = 2\n",
    ")#生成的形状是[16, 16, 64]\n",
    "\n",
    "# 平坦化（flat）。降维\n",
    "flat = tf.reshape(pool2, [-1, 16* 16 * 64])  # 形状 [7 * 7 * 64, ]\n",
    "\n",
    "# 1024 个神经元的全连接层\n",
    "dense = tf.layers.dense(inputs=flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "# Dropout : 丢弃 50%（rate=0.5）\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=0.5)\n",
    "\n",
    "\n",
    "# 10 个神经元的全连接层，这里不用激活函数来做非线性化了\n",
    "logits = tf.layers.dense(inputs=dropout, units=2)  # 输出。形状 [1, 1, 10]\n",
    "\n",
    "# 计算误差（先用 Softmax 计算百分比概率，\n",
    "# 再用 Cross entropy（交叉熵）来计算百分比概率和对应的独热码之间的误差）\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=label_input, logits=logits)\n",
    "\n",
    "#Adam 优化器来最小化误差，学习率 0.001\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "#精度。计算预测值和世纪标签的匹配程度\n",
    "#返回（accuracy， update_op），会创建两个局部变量\n",
    "accuracy = tf.metrics.accuracy(\n",
    "    labels = tf.argmax(label_input, axis = 1),\n",
    "    predictions=tf.argmax(logits, axis=1)\n",
    ")[1]\n",
    "sess = tf.Session()\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "for i in range(50):\n",
    "    #print(i)\n",
    "    train_loss, train_op_ = sess.run([loss, train_op], {data_input: test_data, label_input:test_label})\n",
    "    test_accuracy = sess.run(accuracy, {data_input: test_data, label_input:test_label})\n",
    "    print(\"第 {} 步的 训练损失={:.4f}, 测试精度={:.2f}\".format(i, train_loss, test_accuracy))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "face_xml = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_xml = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "flag = 1\n",
    "while(cap.isOpened()):\n",
    "    ret_flag , Vshow = cap.read()\n",
    "    gray = cv2.cvtColor(Vshow, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_xml.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(Vshow, (x,y),(x+w, y+h),(255,255,255), 1)\n",
    "        roi_face = gray[y:y+h,x:x+w]\n",
    "        roi_color = Vshow[y:y+h,x:x+w]\n",
    "        dst = cv2.resize(roi_face,(64, 64))\n",
    "        dst1 = dst.reshape(1, 64, 64,1).astype(np.float32)/255\n",
    "        with tf.Session() as sess:\n",
    "            init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "            sess.run(init)\n",
    "            test_output = sess.run(logits, {data_input: dst1})\n",
    "            inferred_y = np.argmax(test_output, 1)\n",
    "            x = inferred_y[0]\n",
    "        cv2.putText(Vshow,str(x),(50,50),cv2.FONT_HERSHEY_SIMPLEX,10,(200,100,255),2,cv2.LINE_AA)\n",
    "        cv2.imshow(\"Capture_Test\",Vshow)\n",
    "        k = cv2.waitKey(1) & 0xFF #每帧数据延时 1ms，延时不能为 0，否则读取的结果会是静态帧\n",
    "        if  k == ord('s'):  #若检测到按键 ‘s’，打印字符串\n",
    "            print(cap.get(3))\n",
    "            print(cap.get(4))\n",
    "        elif k == ord('q'): #若检测到按键 ‘q’，退出\n",
    "            cv2.imwrite(\"x1.jpg\",Vshow)\n",
    "            break\n",
    "cap.release() #释放摄像头\n",
    "cv2.destroyAllWindows()#删除建立的全部窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
